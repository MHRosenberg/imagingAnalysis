{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tidy dataset\n",
    "\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pdb\n",
    "\n",
    "## to increase the cell width of the notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "# from sklearn.learning_curve import learning_curve\n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "# from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "def loadTidyTimings(tidyTimingsCSV): \n",
    "    assert os.path.isfile(tidyTimingsCSV), \"desired file does not exist\" \n",
    "    df = pd.read_csv(tidyTimingsCSV, header = None, names = [\"animal\", \"session\", \"trial\", \"stimulus\", \"onsetFrame\", \"offsetFrame\", \"onsetTime\", \"offsetTime\"])\n",
    "    return df \n",
    "\n",
    "def loadTidyCalcium(tidyData): \n",
    "    assert os.path.isfile(tidyData), \"desired file does not exist\" \n",
    "    df = pd.read_csv(tidyData, header = None, names = [\"date\", \"animal\", \"session\", \"trial\", \"stimulus\", \"neuronID\", \"timePt\", \"CaSignal\"])\n",
    "    return df \n",
    "\n",
    "# helper functions to return the number of distinct types in the provided data frame\n",
    "getNumNeurons = lambda df: len(np.unique(df['neuronID'].tolist()))\n",
    "getNeurons = lambda df: np.unique(df['neuronID'].tolist())\n",
    "\n",
    "getNumTrials = lambda df: len(np.unique(df['trial'].tolist()))\n",
    "getTrials = lambda df: np.unique(df['trial'].tolist())\n",
    "\n",
    "getOnsetFrameNum = lambda animal, session, trial: df_timings.loc[(df_timings['animal']==animal) & (df_timings['session']==session) & (df_timings['trial']==trial), ['onsetFrame']].values[0][0]\n",
    "getOffsetFrameNum = lambda animal, session, trial: df_timings.loc[(df_timings['animal']==animal) & (df_timings['session']==session) & (df_timings['trial']==trial), ['offsetFrame']].values[0][0]\n",
    "\n",
    "\n",
    "# pass in pre-filtered data set containing data for only one animal and the same session (ie SAME NEURONS!)\n",
    "def getListsOfTrialIDs(df_animalSession):\n",
    "    ## get trials for both stimuli\n",
    "    df_anmlSessStimA = df_animalSession[df_animalSession['stimulus'] == stimA]\n",
    "    df_anmlSessStimB = df_animalSession[df_animalSession['stimulus'] == stimB]\n",
    "    print(stimA,stimB)\n",
    "\n",
    "    ## get lists of trial numbers of each stimuli's presentations \n",
    "    trials_stimA = np.unique(df_anmlSessStimA['trial'].tolist())\n",
    "    trials_stimB = np.unique(df_anmlSessStimB['trial'].tolist())\n",
    "    print(\"trial IDs for each stimulus type\",trials_stimA,trials_stimB)\n",
    "    return (trials_stimA,trials_stimB)\n",
    "\n",
    "## pass in a data frame with only a single animal and session    \n",
    "def getNumTimePtsPerTrial(df_animalSession, trials_stimA, trials_stimB):\n",
    "\n",
    "    #### get number of timePts in each trial selected above \n",
    "    ## (1 to 3 presentations of the same stimuli exist per session in Prabhat's data)\n",
    "    numTimePtsPerTrial = np.empty((2,max(len(trials_stimA),len(trials_stimB))))\n",
    "    numTimePtsPerTrial[:] = np.nan\n",
    "    stimInd = 0;\n",
    "    for thisStimTypeTrialNums in [trials_stimA, trials_stimB]:\n",
    "        trialInd = 0\n",
    "        for trial in thisStimTypeTrialNums:\n",
    "            inds_thisTrial = (df_animalSession['trial']==trial)\n",
    "            tmp_df_thisTrial = df_animalSession[inds_thisTrial] # gives all time points for all neurons\n",
    "            numNeurons = getNumNeurons(tmp_df_thisTrial) \n",
    "            numTimePtsPerTrial[stimInd,trialInd] = np.sum(inds_thisTrial)/numNeurons \n",
    "            trialInd += 1\n",
    "        stimInd += 1\n",
    "    print('stimuliType x presentationNum (row x col)')    \n",
    "    print(numTimePtsPerTrial) # rows are for stimuli type; cols are presentation of that stimulus\n",
    "    return numTimePtsPerTrial\n",
    "\n",
    "## test candidate comparisons based on whether the number of trials per session and approximate number of timePts match\n",
    "def areNumTrialsPerStimulusEqual(numTimePtsPerTrial):\n",
    "    \n",
    "    ## no trials of either type --> discard this comparison for this animal/session   \n",
    "    if np.all(np.isnan(numTimePtsPerTrial)):\n",
    "        print(\"DISCARDED: neither stimulus type were found for this animal and session\")\n",
    "        return False  # skip to next session (WORK: handle this)\n",
    "        \n",
    "    ## different numbers of trials per stimuli/session --> discard this comparison for this animal/session \n",
    "    elif np.any(np.isnan(numTimePtsPerTrial)): \n",
    "        print(\"DISCARDED: mismatching numbers of trials per stimulus type for this animal/session\")\n",
    "        return False # skip to next session (WORK: handle this)\n",
    "\n",
    "    ## FULFILLED here: condition that allows analysis to proceed to attempted data\n",
    "    elif not np.any(np.isnan(numTimePtsPerTrial)): \n",
    "        print(\"trial numbers match\")\n",
    "    else:\n",
    "        raise RuntimeError('unexpected trial comparison occurred')\n",
    "        return False\n",
    "    \n",
    "    print(\"checking approx num of time points\")\n",
    "\n",
    "## input argument generated from getNumTimePtsPerTrial\n",
    "def areNumTimePtsPerTrialSimilar(numTimePtsPerTrial):\n",
    "    minTPs, maxTPs, meanTPs, stdTPs = timePtStats(numTimePtsPerTrial)             \n",
    "    if (np.abs(minTPs-meanTPs) > (threshTPs_stdFromMean * np.abs(meanTPs-stdTPs))) \\\n",
    "        or (np.abs(maxTPs-meanTPs) > (threshTPs_stdFromMean * np.abs(meanTPs-stdTPs))): \n",
    "        print(\"DISCARDED: variance in trial length is above the user's threshold\")\n",
    "        return False # skip to next session (WORK: handle this)\n",
    "\n",
    "    ### passed all criteria if it made it this far\n",
    "    return True\n",
    "\n",
    "## input argument created by getNumTimePtsPerTrial function\n",
    "def timePtStats(numTimePtsPerTrial):\n",
    "    minTPs = int(np.amin(numTimePtsPerTrial))\n",
    "    maxTPs = int(np.amax(numTimePtsPerTrial))\n",
    "    meanTPs = np.mean(numTimePtsPerTrial)\n",
    "    stdTPs = np.std(numTimePtsPerTrial)\n",
    "\n",
    "    ## useful for debugging\n",
    "#     print('min', minTPs)\n",
    "#     print('max', maxTPs)\n",
    "#     print('std', stdTPs)\n",
    "#     print('mean',meanTPs)\n",
    "#     print('|min-mean|=',np.abs(minTPs-meanTPs))\n",
    "#     print('|max-mean|=',np.abs(maxTPs-meanTPs))\n",
    "#     print('|mean-std|=',np.abs(meanTPs-stdTPs))\n",
    "#     print('thresh * |mean-std|=',(threshTPs_stdFromMean * np.abs(meanTPs-stdTPs)))\n",
    "    \n",
    "    return minTPs, maxTPs, meanTPs, stdTPs\n",
    "\n",
    "def sameNeuronConcat(df_trunc, truncFrameNum):\n",
    "    neuronArr_anmlSess_stimA = np.empty((getNumNeurons(df_trunc),truncFrameNum-1)) # -1 for 0 indexing\n",
    "    neuronArr_anmlSess_stimB = np.empty((getNumNeurons(df_trunc),truncFrameNum-1)) # -1 for 0 indexing\n",
    "    for stimLst in [trials_stimA, trials_stimB]:\n",
    "        if np.array_equal(stimLst,trials_stimA) == True:\n",
    "            print('\\nstimulus:', stimA)\n",
    "        elif np.array_equal(stimLst,trials_stimB) == True:\n",
    "            print('\\nstimulus:', stimB)\n",
    "        else:\n",
    "            raise RuntimeError('unexpected trial concatenation condition occurred')\n",
    "        print('truncation frame: ', truncFrameNum)\n",
    "\n",
    "        ## create temporary sub matrix of concatenated cells for ONE stimulus\n",
    "        tmp_neuronsArr_sameStim = np.empty((getNumNeurons(df_trunc),truncFrameNum)) # for 0 indexing\n",
    "        for trial in stimLst:\n",
    "            print(\"appending same neurons in trial: \", trial)\n",
    "\n",
    "            ##  create temporary sub matrix of same trial all cells\n",
    "            tmp_neuronsArr_sameStim_sameTrial = np.empty((getNumNeurons(df_trunc),truncFrameNum))\n",
    "            for neuron in getNeurons(df_trunc):\n",
    "                tmp_neuronInds = (df_trunc['trial']==trial) & (df_trunc['neuronID']==neuron)\n",
    "                tmp_neuronSeries = df_trunc.loc[tmp_neuronInds,'CaSignal']\n",
    "                \n",
    "                ## pandas to numpy conversion\n",
    "                tmp_neuronVec = tmp_neuronSeries.as_matrix()\n",
    "                \n",
    "                ### WORK\n",
    "#                 print('neuronVec',np.shape(tmp_neuronVec))\n",
    "#                 print('neuronsArr_sameStim_sameTrial', np.shape(tmp_neuronsArr_sameStim_sameTrial))\n",
    "#                 tmp_neuronsArr_sameStim_sameTrial[neuron-1,:] = tmp_neuronVec\n",
    "                ### \n",
    "                \n",
    "            ## append trials to right of same stim if not the first entry\n",
    "            if trial == stimLst[0]:\n",
    "                tmp_neuronsArr_sameStim = np.copy(tmp_neuronsArr_sameStim_sameTrial)\n",
    "            else:    \n",
    "                tmp_neuronsArr_sameStim = np.concatenate((tmp_neuronsArr_sameStim, tmp_neuronsArr_sameStim_sameTrial), axis=1)\n",
    "            print('same stim:', np.shape(tmp_neuronsArr_sameStim))\n",
    "\n",
    "        ## save concatenated data to output variables\n",
    "        if np.array_equal(stimLst,trials_stimA):\n",
    "            neuronArr_anmlSess_stimA = tmp_neuronsArr_sameStim\n",
    "        elif np.array_equal(stimLst,trials_stimB):\n",
    "            neuronArr_anmlSess_stimB = tmp_neuronsArr_sameStim\n",
    "        else:\n",
    "            raise RuntimeError('unexpected same neuron concatenation state occured')\n",
    "        \n",
    "    return neuronArr_anmlSess_stimA, neuronArr_anmlSess_stimB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ concatenate all .csv files exported from matlab into single pandas dataframe df\n",
    "\n",
    "# tidy csv file and dir (use makeTidy_Anderson.m to convert Ann's structure to csv)\n",
    "tidyDataDir = '/home/orthogonull/a_MHR/aa_research/aa_gitResearch/git_ignored/imagingAnalysis/data/2_tidyCSVformat/'\n",
    "tidyDataFileTemplate = 'mouse'\n",
    "tidyDataFileExt = '.csv'\n",
    "tidyTimingsFileAndPath = '/home/orthogonull/a_MHR/aa_research/aa_gitResearch/git_ignored/imagingAnalysis/data/2_tidyCSVformat/stimulusTimings.csv'\n",
    "\n",
    "\n",
    "print(\"loading stimulus timings into df_timings\")\n",
    "timingsLst = []\n",
    "print(tidyTimingsFileAndPath)\n",
    "timingsLst.append(loadTidyTimings(tidyTimingsFileAndPath))\n",
    "df_timings = pd.concat(timingsLst)\n",
    "\n",
    "# get all input files you want to add to the same dataset\n",
    "dataFiles = np.sort(glob.glob(\\\n",
    "    \"/home/orthogonull/a_MHR/aa_research/aa_gitResearch/git_ignored/imagingAnalysis/data/2_tidyCSVformat/mouse*.csv\"))\n",
    "print(\"\\n data files: \\n\", dataFiles)\n",
    "\n",
    "print(\"\\n loading and appending to prior pandas data frame\")\n",
    "dataLst = []\n",
    "\n",
    "for file in dataFiles:\n",
    "    print(file)\n",
    "    dataLst.append(loadTidyCalcium(file))\n",
    "df = pd.concat(dataLst)\n",
    "\n",
    "print('finished loading')\n",
    "\n",
    "############# ALL DATA STORED HERE IN DF\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## survey/search data to prepare for split operation\n",
    "metaStrs = [['dates','date'],['animals','animal'],['sessions','session'],['maxTrials','trial'],['stimuli','stimulus']]\n",
    "\n",
    "print(\"searching over entire data set to get range of various IDs for data (used in subsequent loops)\") \n",
    "\n",
    "## this dictionary holds useful info regarding the range of inputs to loop/search over subsequently\n",
    "metaDct = {}\n",
    "for a,b in metaStrs:\n",
    "    print(a,b)\n",
    "    metaDct[a] = np.unique(df[b].tolist())\n",
    "print(metaDct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### USER PARAMETERS #########\n",
    "\n",
    "threshTPs_stdFromMean = 0.75 ## WORK: make this std of each type and not all types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get all pairs of stimuli\n",
    "stimCmbTpl = tuple(combinations(metaDct['stimuli'],2)) \n",
    "\n",
    "\n",
    "######### MAIN LOOP ##########\n",
    "df_SVM = pd.DataFrame(columns=('dateOfAnalysis', 'dateOfExperiment', 'animal', 'session', 'stimulusA', 'stimulusB', 'SVM_accuracy'))\n",
    "ind_comparison = 0;\n",
    "for (stimA, stimB) in stimCmbTpl:\n",
    "    print((stimA,stimB))\n",
    "    \n",
    "    ## get all data for both trial types\n",
    "    indsBoth = (df['stimulus']==stimA) | (df['stimulus']==stimB)\n",
    "    df_bothStimuli = df[indsBoth]\n",
    "\n",
    "    #### select data by animals and sessions\n",
    "    for animal in metaDct['animals']:\n",
    "        print(\"stimuli comparison num: \", ind_comparison+1)\n",
    "        print('animal: ', animal)\n",
    "        for session in metaDct['sessions']:\n",
    "            print('session:', session)\n",
    "            \n",
    "            ## return subselection of data where the same neurons were recorded\n",
    "            inds_animalSession = (df_bothStimuli['animal'] == animal) & (df_bothStimuli['session'] == session)\n",
    "            df_animalSession = df_bothStimuli[inds_animalSession]\n",
    "            try: \n",
    "                dateOfExperiment = df_animalSession['date'].values[0]\n",
    "            except:\n",
    "                dateOfExperiment = '?'\n",
    "            print('date of exp:', dateOfExperiment)\n",
    "            \n",
    "            # get lists of trial IDs matching stimuli\n",
    "            trials_stimA, trials_stimB = getListsOfTrialIDs(df_animalSession)\n",
    "            \n",
    "            #### skip this comparison <-- if the data don't match in number of trials \n",
    "            numTimePtsPerTrial = getNumTimePtsPerTrial(df_animalSession,trials_stimA,trials_stimB)\n",
    "            if areNumTrialsPerStimulusEqual(numTimePtsPerTrial)==False:\n",
    "                break     \n",
    "                \n",
    "            #### skip this comparison <-- if the data don't match in approx number of timePts\n",
    "            if areNumTimePtsPerTrialSimilar(numTimePtsPerTrial) == False:\n",
    "                break\n",
    "            \n",
    "            #### select time points\n",
    "            minTPs, maxTPs, meanTPs, stdTPs = timePtStats(numTimePtsPerTrial)\n",
    "            truncLst = []\n",
    "            timingsMissing = False\n",
    "            isFirstTrialExamined = True\n",
    "            minStimulusDuration = []\n",
    "            for trial in np.concatenate((trials_stimA,trials_stimB)):\n",
    "                \n",
    "                ## get stimulus timings\n",
    "                onsetFrame = getOnsetFrameNum(animal,session,trial)\n",
    "                offsetFrame = getOffsetFrameNum(animal,session,trial)\n",
    "                stimulusDuration = offsetFrame - onsetFrame\n",
    "#                 print('stimulus duration',stimulusDuration)\n",
    "#                 print('onset frame', onsetFrame)\n",
    "#                 print('offset frame', offsetFrame)\n",
    "                \n",
    "                ## break out of both loops if timings are missing\n",
    "                if np.isnan(onsetFrame) or np.isnan(offsetFrame):\n",
    "                    print('stimulus timing missing --> skipping')\n",
    "                    timingsMissing = True\n",
    "                    break\n",
    "                    \n",
    "                ## set as min if first or has min duration\n",
    "#                 print('min stim dur', minStimulusDuration)\n",
    "#                 print('first trial examined', isFirstTrialExamined)\n",
    "                if isFirstTrialExamined == True:\n",
    "                    isFirstTrialExamined = False\n",
    "                    minStimulusDuration = stimulusDuration[()]\n",
    "                    print('first trial examined --> minStimDur is just the stimDur', minStimulusDuration)\n",
    "                elif stimulusDuration[()] < minStimulusDuration and isFirstTrialExamined == False:\n",
    "                    print('new shortest is: ', stimulusDuration)\n",
    "                    minStimulusDuration = stimulusDuration[()]\n",
    "                minStimulusDuration = int(minStimulusDuration)\n",
    "                \n",
    "            ## timings are missing --> skip the rest of the analysis for this set of data becausing \n",
    "            if timingsMissing == True: \n",
    "                break   \n",
    "            \n",
    "            #### truncate data, then select time points, and save to new df\n",
    "            truncLst = []\n",
    "            print('trial concat', np.concatenate((trials_stimA,trials_stimB)))\n",
    "            for trial in np.concatenate((trials_stimA,trials_stimB)):\n",
    "                onsetFrame = getOnsetFrameNum(animal,session,trial)\n",
    "                offsetFrame_chosen = onsetFrame + minStimulusDuration\n",
    "                print('min stim dur', minStimulusDuration)\n",
    "                print('onset frame', getOnsetFrameNum(animal,session,trial))\n",
    "                print('offsetFrame_chosen: ',offsetFrame_chosen)\n",
    "                \n",
    "                tmp_inds_trunc = (df_animalSession['trial']==trial) & (df_animalSession['timePt'] >= onsetFrame.astype(int)) & (df_animalSession['timePt'] < offsetFrame_chosen.astype(int))\n",
    "                tmp_df_trunc = df_animalSession[tmp_inds_trunc]\n",
    "                truncLst.append(tmp_df_trunc)\n",
    "            df_trunc = pd.concat(truncLst)\n",
    "            \n",
    "            ### just an optional sanity check\n",
    "#             print('num time pts in df_trunc')\n",
    "            getNumTimePtsPerTrial(df_trunc, trials_stimA, trials_stimB) ### work\n",
    "            ###\n",
    "            \n",
    "            #### concatenate same cells \n",
    "            ### loop over and concatenate neurons into the same row if they're the same neuron and stimuli \n",
    "            ##      (ie mouse, session, stimuli)\n",
    "            print(animal,session)\n",
    "            neuronArr_anmlSess_stimA, neuronArr_anmlSess_stimB = sameNeuronConcat(df_trunc, minStimulusDuration)\n",
    "            print('shape', np.shape(neuronArr_anmlSess_stimA), np.shape(neuronArr_anmlSess_stimB))\n",
    "            \n",
    "            ######### SVM #########\n",
    "            \n",
    "            ## create SVM format input by concatenating both classes (stimuli types); y is the labels\n",
    "            print(\"stimA, stimB\",np.shape(neuronArr_anmlSess_stimA), np.shape(neuronArr_anmlSess_stimB))\n",
    "            X = np.concatenate((neuronArr_anmlSess_stimA, neuronArr_anmlSess_stimB), axis = 0)\n",
    "            y = np.empty((neuronArr_anmlSess_stimA.shape[0]+neuronArr_anmlSess_stimB.shape[0]))\n",
    "            y[:neuronArr_anmlSess_stimA.shape[0]] = 0\n",
    "            y[neuronArr_anmlSess_stimB.shape[0]:] = 1\n",
    "            print(\"X:\", X.shape)\n",
    "            print(\"y:\", y.shape)\n",
    "            \n",
    "            print(\"k fold partitioning\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "            \n",
    "            print(\"training SVM\")\n",
    "            clf = svm.SVC(kernel='linear')\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            print(\"testing SVM\")\n",
    "            tmp_score = clf.score(X_test, y_test)\n",
    "            print(tmp_score)\n",
    "            \n",
    "            analysisDate = pd.to_datetime('now')\n",
    "            \n",
    "            df_SVM.loc[ind_comparison] = [analysisDate, dateOfExperiment, animal, session, stimA, stimB, tmp_score]\n",
    "            print(df_SVM)\n",
    "\n",
    "            ind_comparison += 1\n",
    "            \n",
    "            \n",
    "            #             tmp_SVMresult = pd.DataFrame({\"animal\": [animal]})#,{\"testAccuracy\": tmp_score})\n",
    "#             tmp_SVMresult = pd.DataFrame([animal], columns = list([1])) #,{\"testAccuracy\": tmp_score})\n",
    "#             df_SVM.loc[df_SVM.index.max() + 1] = [animal, session, tmp_score]\n",
    "#             df_SVM.loc[totalNumComparisons] = [animal, session, tmp_score]\n",
    "#             df_SVM.loc[totalNumComparisons] = [0,1,2]\n",
    "#             df_SVM = pd.DataFrame({'mouse': animal, 'session': session, 'SVMaccuracy': tmp_score}, index =totalNumComparisons)\n",
    "#             df_SVM.iloc[1] = dict(x=9, y=99)\n",
    "#             df_SVM.append(tmp_SVMresult, ignore_index=True)\n",
    "#             clf.predict(X_test, y_test)\n",
    "            \n",
    "    \n",
    "    ##########33\n",
    "#             cv = ShuffleSplit(X_train.shape[0], n_iter=10, test_size=0.2, random_state=0)\n",
    "            \n",
    "            # WORK: optional gridsearch\n",
    "#             gammas = np.logspace(-6, -1, 10)\n",
    "#             classifier = GridSearchCV(estimator=estimator, cv=cv, param_grid=dict(gamma=gammas))\n",
    "#             classifier.fit(X_train, y_train)\n",
    "            \n",
    "#             title = 'Learning Curves (SVM, linear kernel, $\\gamma=%.6f$)' %classifier.best_estimator_.gamma\n",
    "#             estimator = SVC(kernel='linear', gamma=classifier.best_estimator_.gamma)\n",
    "#             plot_learning_curve(estimator, title, X_train, y_train, cv=cv)\n",
    "#             plt.show()\n",
    "                \n",
    "            print('\\n')\n",
    "        print('########\\n')\n",
    "\n",
    "        \n",
    "print('total number of comparisons: ', ind_comparison+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## buffer cell\n",
    "pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## export timings\n",
    "df_timings.to_csv('df_timings.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save raw svm (animal/session) results to /gitTracked/python/\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(timestr)\n",
    "\n",
    "# Write out raw analysis to csv file\n",
    "OUTPUT_FILENAME = 'SVM_analysis_raw' + timestr + '.csv'\n",
    "df_SVM.to_csv(OUTPUT_FILENAME, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save summary svm data\n",
    "\n",
    "# svmGrouped, df_SVM_summary = df_SVM.groupby(['stimulusA', 'stimulusB'], as_index=False)\n",
    "\n",
    "# f = {'SVM_accuracy':['sum','mean'], 'B':['prod']}\n",
    "\n",
    "stimGrouped = df_SVM.groupby(['stimulusA','stimulusB'], as_index=True)\n",
    "df_SVM_summaryDesc = stimGrouped.describe()\n",
    "\n",
    "print(stimGrouped.describe())      \n",
    "\n",
    "# Write out raw analysis to csv file\n",
    "OUTPUT_FILENAME = 'SVM_analysis_summary' + timestr + '.csv'\n",
    "df_SVM_summaryDesc.to_csv(OUTPUT_FILENAME, header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## inspect grouped-by object created above\n",
    "\n",
    "for key, item in stimGrouped:\n",
    "    print(stimGrouped.get_group(key), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratData = df.loc[df['stimulusType'] == 'rat',:]\n",
    "ussData = df.loc[df['stimulusType'] == 'USS',:]\n",
    "\n",
    "print(ussData)\n",
    "\n",
    "\n",
    "\n",
    "df.corr()\n",
    "\n",
    "\n",
    "# Rename the impact force column\n",
    "df = df.rename(columns={'impact force (mN)': 'impf'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
