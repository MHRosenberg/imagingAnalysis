{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tidy dataset\n",
    "\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import glob\n",
    "\n",
    "#import numpy as np\n",
    "#import loadTidyCSV.py\n",
    "\n",
    "def loadTidy(tidyData): \n",
    "    assert os.path.isfile(tidyData), \"desired file does not exist\" \n",
    "    df = pd.read_csv(tidyData, header = None, names = [\"date\", \"animal\", \"session\", \"trial\", \"stimulus\", \"neuronID\", \"timePt\", \"CaSignal\"])\n",
    "    return df \n",
    "\n",
    "# helper function to return the number of neurons in the provided data frame\n",
    "getNumNeurons = lambda df: len(np.unique(df['neuronID'].tolist()))\n",
    "\n",
    "## test candidate comparisons based on whether the number of trials per session and approximate number of timePts match\n",
    "def isDataComparable(numTimePtsPerTrial):\n",
    "    \n",
    "    ## no trials of either type --> discard this comparison for this animal/session   \n",
    "    if np.all(np.isnan(numTimePtsPerTrial)):\n",
    "        print(\"DISCARDED: neither stimulus type were found for this animal and session\")\n",
    "        return False  # skip to next session (WORK: handle this)\n",
    "        \n",
    "    ## different numbers of trials per stimuli/session --> discard this comparison for this animal/session \n",
    "    elif np.any(np.isnan(numTimePtsPerTrial)): \n",
    "        print(\"DISCARDED: mismatching numbers of trials per stimulus type for this animal/session\")\n",
    "        return False # skip to next session (WORK: handle this)\n",
    "\n",
    "    ## FULFILLED here: condition that allows analysis to proceed to attempted data\n",
    "    elif not np.any(np.isnan(numTimePtsPerTrial)): \n",
    "        print(\"trial numbers match\")\n",
    "    else:\n",
    "        raise RuntimeError('unexpected trial comparison occurred')\n",
    "        return False\n",
    "    \n",
    "    print(\"checking approx num of time points\")\n",
    "\n",
    "    #### discard this comparison for this animal/session if number of time points are too dissimilar\n",
    "    minTPs, maxTPs, meanTPs, stdTPs = timePtStats(numTimePtsPerTrial)            \n",
    "\n",
    "    if (np.abs(minTPs-meanTPs) > (threshTPs_stdFromMean * np.abs(meanTPs-stdTPs))) \\\n",
    "        or (np.abs(maxTPs-meanTPs) > (threshTPs_stdFromMean * np.abs(meanTPs-stdTPs))): \n",
    "        print(\"DISCARDED: variance in trial length is above the user's threshold\")\n",
    "        return False # skip to next session (WORK: handle this)\n",
    "\n",
    "    ### passed all criteria if it made it this far\n",
    "    return (True, minTPs) \n",
    "\n",
    "## pass in a data frame with only a single animal and session    \n",
    "def getNumTimePtsPerTrial(df_animalSession):\n",
    "## get both stim\n",
    "    df_anmlSessStimA = df_animalSession[df_animalSession['stimulus'] == stimA]\n",
    "    df_anmlSessStimB = df_animalSession[df_animalSession['stimulus'] == stimB]\n",
    "    print(stimA,stimB)\n",
    "\n",
    "    ## get lists of trial numbers of each stimuli's presentations \n",
    "    trials_stimA = np.unique(df_anmlSessStimA['trial'].tolist())\n",
    "    trials_stimB = np.unique(df_anmlSessStimB['trial'].tolist())\n",
    "#     print(\"trial IDs for each stimulus type\",trials_stimA,trials_stimB)\n",
    "    print(trials_stimA,trials_stimB)\n",
    "\n",
    "    #### get number of timePts in each trial selected above \n",
    "    ## (1 to 3 presentations of the same stimuli exist per session in Prabhat's data)\n",
    "    numTimePtsPerTrial = np.empty((2,max(len(trials_stimA),len(trials_stimB))))\n",
    "    numTimePtsPerTrial[:] = np.nan\n",
    "    stimInd = 0;\n",
    "    for thisStimTypeTrialNums in [trials_stimA, trials_stimB]:\n",
    "        trialInd = 0\n",
    "        for trial in thisStimTypeTrialNums:\n",
    "            inds_thisTrial = (df_animalSession['trial']==trial)\n",
    "            tmp_df_thisTrial = df_animalSession[inds_thisTrial] # gives all time points for all neurons\n",
    "            numNeurons = len(np.unique(tmp_df_thisTrial['neuronID'].tolist())) \n",
    "            numTimePtsPerTrial[stimInd,trialInd] = np.sum(inds_thisTrial)/numNeurons \n",
    "            trialInd += 1\n",
    "        stimInd += 1\n",
    "    print(numTimePtsPerTrial) # rows are for stimuli type; cols are presentation of that stimulus\n",
    "    return numTimePtsPerTrial\n",
    "\n",
    "## input argument created by getNumTimePtsPerTrial function\n",
    "def timePtStats(numTimePtsPerTrial):\n",
    "    minTPs = int(np.amin(numTimePtsPerTrial))\n",
    "    maxTPs = int(np.amax(numTimePtsPerTrial))\n",
    "    meanTPs = np.mean(numTimePtsPerTrial)\n",
    "    stdTPs = np.std(numTimePtsPerTrial)\n",
    "    print('min', minTPs)\n",
    "    print('max', maxTPs)\n",
    "    print('std', stdTPs)\n",
    "    print('mean',meanTPs)\n",
    "    print('|min-mean|=',np.abs(minTPs-meanTPs))\n",
    "    print('|max-mean|=',np.abs(maxTPs-meanTPs))\n",
    "    print('|mean-std|=',np.abs(meanTPs-stdTPs))\n",
    "    print('thresh * |mean-std|=',(threshTPs_stdFromMean * np.abs(meanTPs-stdTPs)))\n",
    "    return minTPs, maxTPs, meanTPs, stdTPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data files: \n",
      " [ '/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse1.csv'\n",
      " '/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse2.csv'\n",
      " '/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse3.csv'\n",
      " '/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse4.csv'\n",
      " '/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse5.csv']\n",
      "\n",
      " loading and appending to prior pandas data frame\n",
      "/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse1.csv\n",
      "/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse2.csv\n",
      "/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse3.csv\n",
      "/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse4.csv\n",
      "/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse5.csv\n",
      "finished loading\n"
     ]
    }
   ],
   "source": [
    "################ concatenate all .csv files exported from matlab into single pandas dataframe df\n",
    "\n",
    "# tidy csv file and dir (use makeTidy_Anderson.m to convert Ann's structure to csv)\n",
    "tidyDataDir = '/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/'\n",
    "tidyDataFileTemplate = 'mouse'\n",
    "tidyDataFileExt = '.csv'\n",
    "\n",
    "# get all input files you want to add to the same dataset\n",
    "dataFiles = np.sort(glob.glob(\\\n",
    "    \"/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse*.csv\"))\n",
    "print(\"data files: \\n\", dataFiles)\n",
    "\n",
    "\n",
    "print(\"\\n loading and appending to prior pandas data frame\")\n",
    "dataLst = []\n",
    "for file in dataFiles:\n",
    "    print(file)\n",
    "    dataLst.append(loadTidy(file))\n",
    "df = pd.concat(dataLst)\n",
    "\n",
    "print('finished loading')\n",
    "\n",
    "############# ALL DATA STORED HERE IN DF\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching over entire data set to get range of various IDs for data (used subsequent loops)\n",
      "dates date\n",
      "animals animal\n",
      "sessions session\n",
      "maxTrials trial\n",
      "stimuli stimulus\n",
      "{'dates': array(['2017_05_00'], \n",
      "      dtype='<U10'), 'animals': array([1, 3, 4, 5, 7]), 'sessions': array([1, 2, 3]), 'maxTrials': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "       18, 19, 20, 21]), 'stimuli': array(['USS', 'baseline', 'female', 'male', 'mineral oil odor',\n",
      "       'peanut odor', 'pred odor', 'rat', 'tone', 'toy'], \n",
      "      dtype='<U16')}\n"
     ]
    }
   ],
   "source": [
    "## survey/search data to prepare for split operation\n",
    "metaStrs = [['dates','date'],['animals','animal'],['sessions','session'],['maxTrials','trial'],['stimuli','stimulus']]\n",
    "\n",
    "print(\"searching over entire data set to get range of various IDs for data (used subsequent loops)\") \n",
    "\n",
    "## this dictionary holds useful info regarding the range of inputs to loop/search over subsequently\n",
    "metaDct = {}\n",
    "for a,b in metaStrs:\n",
    "    print(a,b)\n",
    "    metaDct[a] = np.unique(df[b].tolist())\n",
    "print(metaDct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### USER PARAMETERS #########\n",
    "threshTPs_stdFromMean = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('USS', 'baseline')\n",
      "animal:  1\n",
      "session: 1\n",
      "USS baseline\n",
      "[ 5 10 16] [ 1  8 15]\n",
      "[[ 1117.  1116.  1117.]\n",
      " [  370.   363.  1476.]]\n",
      "trial numbers match\n",
      "checking approx num of time points\n",
      "min 363\n",
      "max 1476\n",
      "std 415.865663406\n",
      "mean 926.5\n",
      "|min-mean|= 563.5\n",
      "|max-mean|= 549.5\n",
      "|mean-std|= 510.634336594\n",
      "thresh * |mean-std|= 510.634336594\n",
      "DISCARDED: variance in trial length is above the user's threshold\n",
      "########\n",
      "\n",
      "animal:  3\n",
      "session: 1\n",
      "USS baseline\n",
      "[ 4 11 17] [ 1  8 15]\n",
      "[[ 1267.  1127.  1123.]\n",
      " [  674.   682.   678.]]\n",
      "trial numbers match\n",
      "checking approx num of time points\n",
      "min 674\n",
      "max 1267\n",
      "std 251.671357572\n",
      "mean 925.166666667\n",
      "|min-mean|= 251.166666667\n",
      "|max-mean|= 341.833333333\n",
      "|mean-std|= 673.495309094\n",
      "thresh * |mean-std|= 673.495309094\n",
      "trial:  1\n",
      "\n",
      " appending same neurons in trial:  1\n",
      "num neurons in this trial:  30\n",
      "min 20220\n",
      "shape (674,) (30, 20220)\n",
      "num neurons 30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (674) into shape (20220)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-5566f587613a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shape'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_neuronVec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_sameStimNeuronsArr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num neurons'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetNumNeurons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_trunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                     \u001b[0mtmp_sameStimNeuronsArr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_neuronVec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_sameStimNeuronsArr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0;31m#                         print('neuronDF',tmp_neuronDF)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (674) into shape (20220)"
     ]
    }
   ],
   "source": [
    "### get all pairs of stimuli\n",
    "stimCmbTpl = tuple(combinations(metaDct['stimuli'],2)) \n",
    "\n",
    "######### MAIN LOOP ##########\n",
    "totalNumComparisons = 0;\n",
    "for (stimA, stimB) in stimCmbTpl:\n",
    "    print((stimA,stimB))\n",
    "    \n",
    "    ## get all data for both trial types\n",
    "    indsBoth = (df['stimulus']==stimA) | (df['stimulus']==stimB)\n",
    "    df_bothStimuli = df[indsBoth]\n",
    "\n",
    "    #### select data by animals and sessions\n",
    "    for animal in metaDct['animals']:\n",
    "        print('animal: ', animal)\n",
    "        for session in metaDct['sessions']:\n",
    "            print('session:', session)\n",
    "            inds_animalSession = (df_bothStimuli['animal'] == animal) & (df_bothStimuli['session'] == session)\n",
    "            df_animalSession = df_bothStimuli[inds_animalSession]\n",
    "            \n",
    "            #### skip this comparison if the data don't match in number of trials or approx number of timePts\n",
    "            numTimePtsPerTrial = getNumTimePtsPerTrial(df_animalSession)\n",
    "            if isDataComparable(numTimePtsPerTrial)==False:\n",
    "                break            \n",
    "            \n",
    "            ## truncate longer trials to shortest trial and save to new df\n",
    "            truncLst = []\n",
    "            for trial in np.concatenate((trials_stimA,trials_stimB)):\n",
    "                tmp_inds_trunc = (df_animalSession['trial']==trial) & (df_animalSession['timePt'] < minTPs)\n",
    "                tmp_df_trunc = df_animalSession[tmp_inds_trunc]\n",
    "                truncLst.append(tmp_df_trunc)\n",
    "            df_trunc = pd.concat(truncLst)\n",
    "                    \n",
    "            ## concatenate same cells \n",
    "            NUM_ROWS_INITIALIZE = 15 # this value shouldn't matter since it should expand if needed \n",
    "            neuronArr_anmlSess = np.empty((NUM_ROWS_INITIALIZE,minTPs))\n",
    "        \n",
    "            trials = np.unique(df_trunc['trial'].tolist())\n",
    "            for trial in trials:\n",
    "                neurons = np.unique(data['neuronID'].tolist())\n",
    "                print(\"trial: \", trial)\n",
    "                print(\"\\n appending same neurons in trial: \", trial)\n",
    "                print(\"num neurons in this trial: \",len(neurons))\n",
    "                \n",
    "                tmp_sameStimNeuronsArr = np.empty((len(neurons),minTPs))\n",
    "                for neuron in neurons:\n",
    "                    tmp_neuronInds = (df_trunc['trial']==trial) & (df_trunc['neuronID']==neuron)\n",
    "                    tmp_neuronSeries = df_trunc.loc[tmp_neuronInds,'CaSignal']\n",
    "                    tmp_neuronVec = tmp_neuronSeries.as_matrix()\n",
    "                    \n",
    "                    print('min',minTPs)\n",
    "                    print('shape',np.shape(tmp_neuronVec),np.shape(tmp_sameStimNeuronsArr))\n",
    "                    print('num neurons', getNumNeurons(df_trunc))\n",
    "                    tmp_sameStimNeuronsArr[neuron,:] = tmp_neuronVec \n",
    "                    print(tmp_sameStimNeuronsArr)\n",
    "                    #                         print('neuronDF',tmp_neuronDF)\n",
    "                    #                         tmp_neuronTraceVec =\n",
    "\n",
    "   \n",
    "            totalNumComparisons += 1    \n",
    "            print('\\n')\n",
    "        print('########\\n')\n",
    "\n",
    "print('total number of comparisons: ', totalNumComparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1485"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#                     tmp_trialInds = (data['trial']==trial) \n",
    "#                     print(np.sum(tmp_trialInds))\n",
    "#                     tmp_mat = data[tmp_trialInds].as_matrix()\n",
    "#                     print(tmp_mat)\n",
    "#                     print(type(tmp_neuronConcatArr))\n",
    "#                     np.append(tmp_neuronConcatArr,tmp_mat)\n",
    "#                     print(tmp_neuronConcatArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 10  5 15]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26808\n"
     ]
    }
   ],
   "source": [
    "testInds = (df['animal']==1) & (df['session']==1) & (df['stimulus']=='USS') & (df['trial']==5)\n",
    "print(np.sum(testInds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.unique(df_anmlSessStimA[df_anmlSessStimA['trial'] == trialA].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               date  animalNum  sessionNum  trialNum stimulusType  neuronID  \\\n",
      "36240    2017_05_00          1           1         3          rat         1   \n",
      "36241    2017_05_00          1           1         3          rat         1   \n",
      "36242    2017_05_00          1           1         3          rat         1   \n",
      "36243    2017_05_00          1           1         3          rat         1   \n",
      "36244    2017_05_00          1           1         3          rat         1   \n",
      "36245    2017_05_00          1           1         3          rat         1   \n",
      "36246    2017_05_00          1           1         3          rat         1   \n",
      "36247    2017_05_00          1           1         3          rat         1   \n",
      "36248    2017_05_00          1           1         3          rat         1   \n",
      "36249    2017_05_00          1           1         3          rat         1   \n",
      "36250    2017_05_00          1           1         3          rat         1   \n",
      "36251    2017_05_00          1           1         3          rat         1   \n",
      "36252    2017_05_00          1           1         3          rat         1   \n",
      "36253    2017_05_00          1           1         3          rat         1   \n",
      "36254    2017_05_00          1           1         3          rat         1   \n",
      "36255    2017_05_00          1           1         3          rat         1   \n",
      "36256    2017_05_00          1           1         3          rat         1   \n",
      "36257    2017_05_00          1           1         3          rat         1   \n",
      "36258    2017_05_00          1           1         3          rat         1   \n",
      "36259    2017_05_00          1           1         3          rat         1   \n",
      "36260    2017_05_00          1           1         3          rat         1   \n",
      "36261    2017_05_00          1           1         3          rat         1   \n",
      "36262    2017_05_00          1           1         3          rat         1   \n",
      "36263    2017_05_00          1           1         3          rat         1   \n",
      "36264    2017_05_00          1           1         3          rat         1   \n",
      "36265    2017_05_00          1           1         3          rat         1   \n",
      "36266    2017_05_00          1           1         3          rat         1   \n",
      "36267    2017_05_00          1           1         3          rat         1   \n",
      "36268    2017_05_00          1           1         3          rat         1   \n",
      "36269    2017_05_00          1           1         3          rat         1   \n",
      "...             ...        ...         ...       ...          ...       ...   \n",
      "1585256  2017_05_00          1           3        21          rat        21   \n",
      "1585257  2017_05_00          1           3        21          rat        21   \n",
      "1585258  2017_05_00          1           3        21          rat        21   \n",
      "1585259  2017_05_00          1           3        21          rat        21   \n",
      "1585260  2017_05_00          1           3        21          rat        21   \n",
      "1585261  2017_05_00          1           3        21          rat        21   \n",
      "1585262  2017_05_00          1           3        21          rat        21   \n",
      "1585263  2017_05_00          1           3        21          rat        21   \n",
      "1585264  2017_05_00          1           3        21          rat        21   \n",
      "1585265  2017_05_00          1           3        21          rat        21   \n",
      "1585266  2017_05_00          1           3        21          rat        21   \n",
      "1585267  2017_05_00          1           3        21          rat        21   \n",
      "1585268  2017_05_00          1           3        21          rat        21   \n",
      "1585269  2017_05_00          1           3        21          rat        21   \n",
      "1585270  2017_05_00          1           3        21          rat        21   \n",
      "1585271  2017_05_00          1           3        21          rat        21   \n",
      "1585272  2017_05_00          1           3        21          rat        21   \n",
      "1585273  2017_05_00          1           3        21          rat        21   \n",
      "1585274  2017_05_00          1           3        21          rat        21   \n",
      "1585275  2017_05_00          1           3        21          rat        21   \n",
      "1585276  2017_05_00          1           3        21          rat        21   \n",
      "1585277  2017_05_00          1           3        21          rat        21   \n",
      "1585278  2017_05_00          1           3        21          rat        21   \n",
      "1585279  2017_05_00          1           3        21          rat        21   \n",
      "1585280  2017_05_00          1           3        21          rat        21   \n",
      "1585281  2017_05_00          1           3        21          rat        21   \n",
      "1585282  2017_05_00          1           3        21          rat        21   \n",
      "1585283  2017_05_00          1           3        21          rat        21   \n",
      "1585284  2017_05_00          1           3        21          rat        21   \n",
      "1585285  2017_05_00          1           3        21          rat        21   \n",
      "\n",
      "         timePt  CaSignal  \n",
      "36240         1   4.68050  \n",
      "36241         2   5.61680  \n",
      "36242         3   3.55400  \n",
      "36243         4   5.11350  \n",
      "36244         5   2.54780  \n",
      "36245         6   3.39200  \n",
      "36246         7   3.85930  \n",
      "36247         8   3.73370  \n",
      "36248         9   2.04470  \n",
      "36249        10   2.02200  \n",
      "36250        11   3.69610  \n",
      "36251        12   4.18500  \n",
      "36252        13   4.83710  \n",
      "36253        14   2.39510  \n",
      "36254        15   1.94470  \n",
      "36255        16   2.83460  \n",
      "36256        17   3.81380  \n",
      "36257        18   3.21150  \n",
      "36258        19   3.32660  \n",
      "36259        20   5.63980  \n",
      "36260        21   1.06760  \n",
      "36261        22   2.53410  \n",
      "36262        23   4.79900  \n",
      "36263        24   2.33430  \n",
      "36264        25   2.27690  \n",
      "36265        26   4.69630  \n",
      "36266        27   4.19110  \n",
      "36267        28   1.20030  \n",
      "36268        29   1.21780  \n",
      "36269        30   3.74280  \n",
      "...         ...       ...  \n",
      "1585256    1165   4.43220  \n",
      "1585257    1166   3.29190  \n",
      "1585258    1167   3.90910  \n",
      "1585259    1168   3.87110  \n",
      "1585260    1169   1.79130  \n",
      "1585261    1170   3.84470  \n",
      "1585262    1171   1.99820  \n",
      "1585263    1172   5.00430  \n",
      "1585264    1173   2.64420  \n",
      "1585265    1174   3.15470  \n",
      "1585266    1175   2.38570  \n",
      "1585267    1176   3.45930  \n",
      "1585268    1177   3.39460  \n",
      "1585269    1178   1.94500  \n",
      "1585270    1179   1.88260  \n",
      "1585271    1180   2.20360  \n",
      "1585272    1181   0.26918  \n",
      "1585273    1182   2.61460  \n",
      "1585274    1183   1.04830  \n",
      "1585275    1184   0.64471  \n",
      "1585276    1185   1.60720  \n",
      "1585277    1186   2.73410  \n",
      "1585278    1187   4.24780  \n",
      "1585279    1188   3.13810  \n",
      "1585280    1189   3.38300  \n",
      "1585281    1190   5.45860  \n",
      "1585282    1191   2.43990  \n",
      "1585283    1192   2.88570  \n",
      "1585284    1193   2.41010  \n",
      "1585285    1194  -1.49270  \n",
      "\n",
      "[242191 rows x 8 columns]\n",
      "reached end of file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# gb = df.groupby(['stimulusType']).get_group('rat')\n",
    "\n",
    "stimGrouped = df.groupby('stimulusType')\n",
    "ratGrpd = stimGrouped.get_group('rat')\n",
    "\n",
    "print(ratGrpd)\n",
    "\n",
    "print('reached end of file')\n",
    "\n",
    "gb = df.groupby('stimulusType')\n",
    "\n",
    "df_means = gb.apply(np.mean)\n",
    "df_means\n",
    "\n",
    "for stimType in gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'stimulusType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/home/orthogonull/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2392\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2393\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2394\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5239)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5085)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20405)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'stimulusType'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-1ce72105a90a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mratData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stimulusType'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mussData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stimulusType'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'USS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mussData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/orthogonull/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2060\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2062\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/orthogonull/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/orthogonull/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/orthogonull/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/orthogonull/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2393\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2395\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5239)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5085)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20405)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'stimulusType'"
     ]
    }
   ],
   "source": [
    "ratData = df.loc[df['stimulusType'] == 'rat',:]\n",
    "ussData = df.loc[df['stimulusType'] == 'USS',:]\n",
    "\n",
    "print(ussData)\n",
    "\n",
    "# slicing\n",
    "df_big_force = df.loc[df['impact force (mN)'] > 1000, :]\n",
    "\n",
    "df = pd.concat((df_low, df_high), axis=1)\n",
    "\n",
    "# Specify indices we want (note parentheses holding each Boolean)\n",
    "inds = (df['food density'] == 'high') & (df['cross-sectional area (sq micron)'] > 2000)\n",
    "\n",
    "# Pull out areas\n",
    "df.loc[inds, 'cross-sectional area (sq micron)']\n",
    "\n",
    "df.corr()\n",
    "\n",
    "\n",
    "# Rename the impact force column\n",
    "df = df.rename(columns={'impact force (mN)': 'impf'})\n",
    "\n",
    "\n",
    "\n",
    "# Write out DataFrame\n",
    "df.to_csv('xa_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
