{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orthogonull/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# load tidy dataset\n",
    "\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "  \n",
    "\n",
    "#import numpy as np\n",
    "#import loadTidyCSV.py\n",
    "\n",
    "def loadTidy(tidyData): \n",
    "    assert os.path.isfile(tidyData), \"desired file does not exist\" \n",
    "    df = pd.read_csv(tidyData, header = None, names = [\"date\", \"animal\", \"session\", \"trial\", \"stimulus\", \"neuronID\", \"timePt\", \"CaSignal\"])\n",
    "    return df \n",
    "\n",
    "# helper functions to return the number of distinct types in the provided data frame\n",
    "getNumNeurons = lambda df: len(np.unique(df['neuronID'].tolist()))\n",
    "getNeurons = lambda df: np.unique(df['neuronID'].tolist())\n",
    "\n",
    "getNumTrials = lambda df: len(np.unique(df['trial'].tolist()))\n",
    "getTrials = lambda df: np.unique(df['trial'].tolist())\n",
    "\n",
    "\n",
    "# pass in pre-filtered data set containing data for only one animal and the same session (ie SAME NEURONS!)\n",
    "def getListsOfTrialIDs(df_animalSession):\n",
    "    ## get trials for both stimuli\n",
    "    df_anmlSessStimA = df_animalSession[df_animalSession['stimulus'] == stimA]\n",
    "    df_anmlSessStimB = df_animalSession[df_animalSession['stimulus'] == stimB]\n",
    "    print(stimA,stimB)\n",
    "\n",
    "    ## get lists of trial numbers of each stimuli's presentations \n",
    "    trials_stimA = np.unique(df_anmlSessStimA['trial'].tolist())\n",
    "    trials_stimB = np.unique(df_anmlSessStimB['trial'].tolist())\n",
    "    print(\"trial IDs for each stimulus type\",trials_stimA,trials_stimB)\n",
    "    return (trials_stimA,trials_stimB)\n",
    "\n",
    "## pass in a data frame with only a single animal and session    \n",
    "def getNumTimePtsPerTrial(df_animalSession, trials_stimA, trials_stimB):\n",
    "\n",
    "    #### get number of timePts in each trial selected above \n",
    "    ## (1 to 3 presentations of the same stimuli exist per session in Prabhat's data)\n",
    "    numTimePtsPerTrial = np.empty((2,max(len(trials_stimA),len(trials_stimB))))\n",
    "    numTimePtsPerTrial[:] = np.nan\n",
    "    stimInd = 0;\n",
    "    for thisStimTypeTrialNums in [trials_stimA, trials_stimB]:\n",
    "        trialInd = 0\n",
    "        for trial in thisStimTypeTrialNums:\n",
    "            inds_thisTrial = (df_animalSession['trial']==trial)\n",
    "            tmp_df_thisTrial = df_animalSession[inds_thisTrial] # gives all time points for all neurons\n",
    "            numNeurons = getNumNeurons(tmp_df_thisTrial) \n",
    "            numTimePtsPerTrial[stimInd,trialInd] = np.sum(inds_thisTrial)/numNeurons \n",
    "            trialInd += 1\n",
    "        stimInd += 1\n",
    "    print(numTimePtsPerTrial) # rows are for stimuli type; cols are presentation of that stimulus\n",
    "    return numTimePtsPerTrial\n",
    "\n",
    "## test candidate comparisons based on whether the number of trials per session and approximate number of timePts match\n",
    "def areNumTrialsPerStimulusEqual(numTimePtsPerTrial):\n",
    "    \n",
    "    ## no trials of either type --> discard this comparison for this animal/session   \n",
    "    if np.all(np.isnan(numTimePtsPerTrial)):\n",
    "        print(\"DISCARDED: neither stimulus type were found for this animal and session\")\n",
    "        return False  # skip to next session (WORK: handle this)\n",
    "        \n",
    "    ## different numbers of trials per stimuli/session --> discard this comparison for this animal/session \n",
    "    elif np.any(np.isnan(numTimePtsPerTrial)): \n",
    "        print(\"DISCARDED: mismatching numbers of trials per stimulus type for this animal/session\")\n",
    "        return False # skip to next session (WORK: handle this)\n",
    "\n",
    "    ## FULFILLED here: condition that allows analysis to proceed to attempted data\n",
    "    elif not np.any(np.isnan(numTimePtsPerTrial)): \n",
    "        print(\"trial numbers match\")\n",
    "    else:\n",
    "        raise RuntimeError('unexpected trial comparison occurred')\n",
    "        return False\n",
    "    \n",
    "    print(\"checking approx num of time points\")\n",
    "\n",
    "## input argument generated from getNumTimePtsPerTrial\n",
    "def areNumTimePtsPerTrialSimilar(numTimePtsPerTrial):\n",
    "    minTPs, maxTPs, meanTPs, stdTPs = timePtStats(numTimePtsPerTrial)             \n",
    "    if (np.abs(minTPs-meanTPs) > (threshTPs_stdFromMean * np.abs(meanTPs-stdTPs))) \\\n",
    "        or (np.abs(maxTPs-meanTPs) > (threshTPs_stdFromMean * np.abs(meanTPs-stdTPs))): \n",
    "        print(\"DISCARDED: variance in trial length is above the user's threshold\")\n",
    "        return False # skip to next session (WORK: handle this)\n",
    "\n",
    "    ### passed all criteria if it made it this far\n",
    "    return True\n",
    "\n",
    "## input argument created by getNumTimePtsPerTrial function\n",
    "def timePtStats(numTimePtsPerTrial):\n",
    "    minTPs = int(np.amin(numTimePtsPerTrial))\n",
    "    maxTPs = int(np.amax(numTimePtsPerTrial))\n",
    "    meanTPs = np.mean(numTimePtsPerTrial)\n",
    "    stdTPs = np.std(numTimePtsPerTrial)\n",
    "\n",
    "    ## useful for debugging\n",
    "#     print('min', minTPs)\n",
    "#     print('max', maxTPs)\n",
    "#     print('std', stdTPs)\n",
    "#     print('mean',meanTPs)\n",
    "#     print('|min-mean|=',np.abs(minTPs-meanTPs))\n",
    "#     print('|max-mean|=',np.abs(maxTPs-meanTPs))\n",
    "#     print('|mean-std|=',np.abs(meanTPs-stdTPs))\n",
    "#     print('thresh * |mean-std|=',(threshTPs_stdFromMean * np.abs(meanTPs-stdTPs)))\n",
    "    \n",
    "    return minTPs, maxTPs, meanTPs, stdTPs\n",
    "\n",
    "def sameNeuronConcat(df_trunc, minTPs):\n",
    "    neuronArr_anmlSess_stimA = np.empty((getNumNeurons(df_trunc),minTPs-1)) # -1 for 0 indexing\n",
    "    neuronArr_anmlSess_stimB = np.empty((getNumNeurons(df_trunc),minTPs-1)) # -1 for 0 indexing\n",
    "    for stimLst in [trials_stimA, trials_stimB]:\n",
    "        if np.array_equal(stimLst,trials_stimA) == True:\n",
    "            print('\\nstimulus:', stimA)\n",
    "        elif np.array_equal(stimLst,trials_stimB) == True:\n",
    "            print('\\nstimulus:', stimB)\n",
    "        else:\n",
    "            raise RuntimeError('unexpected trial concatenation condition occurred')\n",
    "        print('selected minTPs: ', minTPs)\n",
    "\n",
    "        ## create temporary sub matrix of concatenated cells for ONE stimulus\n",
    "        tmp_neuronsArr_sameStim = np.empty((getNumNeurons(df_trunc),minTPs)) # for 0 indexing\n",
    "        for trial in stimLst:\n",
    "            print(\"appending same neurons in trial: \", trial)\n",
    "\n",
    "            ##  create temporary sub matrix of same trial all cells\n",
    "            tmp_neuronsArr_sameStim_sameTrial = np.empty((getNumNeurons(df_trunc),minTPs))\n",
    "            for neuron in getNeurons(df_trunc):\n",
    "                tmp_neuronInds = (df_trunc['trial']==trial) & (df_trunc['neuronID']==neuron)\n",
    "                tmp_neuronSeries = df_trunc.loc[tmp_neuronInds,'CaSignal']\n",
    "                tmp_neuronVec = tmp_neuronSeries.as_matrix()\n",
    "                tmp_neuronsArr_sameStim_sameTrial[neuron-1,:] = tmp_neuronVec\n",
    "\n",
    "            ## append trials to right of same stim if not the first entry\n",
    "            if trial == stimLst[0]:\n",
    "                tmp_neuronsArr_sameStim = np.copy(tmp_neuronsArr_sameStim_sameTrial)\n",
    "            else:    \n",
    "                tmp_neuronsArr_sameStim = np.concatenate((tmp_neuronsArr_sameStim, tmp_neuronsArr_sameStim_sameTrial), axis=1)\n",
    "            print('same stim:', np.shape(tmp_neuronsArr_sameStim))\n",
    "\n",
    "        ## save concatenated data to output variables\n",
    "        if np.array_equal(stimLst,trials_stimA):\n",
    "            neuronArr_anmlSess_stimA = tmp_neuronsArr_sameStim\n",
    "        elif np.array_equal(stimLst,trials_stimB):\n",
    "            neuronArr_anmlSess_stimB = tmp_neuronsArr_sameStim\n",
    "        else:\n",
    "            raise RuntimeError('unexpected same neuron concatenation state occured')\n",
    "        \n",
    "    return neuronArr_anmlSess_stimA, neuronArr_anmlSess_stimB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data files: \n",
      " [ '/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse1.csv'\n",
      " '/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse2.csv'\n",
      " '/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse3.csv'\n",
      " '/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse4.csv'\n",
      " '/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse5.csv']\n",
      "\n",
      " loading and appending to prior pandas data frame\n",
      "/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse1.csv\n",
      "/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse2.csv\n",
      "/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse3.csv\n",
      "/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse4.csv\n",
      "/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse5.csv\n",
      "finished loading\n"
     ]
    }
   ],
   "source": [
    "################ concatenate all .csv files exported from matlab into single pandas dataframe df\n",
    "\n",
    "# tidy csv file and dir (use makeTidy_Anderson.m to convert Ann's structure to csv)\n",
    "tidyDataDir = '/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/'\n",
    "tidyDataFileTemplate = 'mouse'\n",
    "tidyDataFileExt = '.csv'\n",
    "\n",
    "# get all input files you want to add to the same dataset\n",
    "dataFiles = np.sort(glob.glob(\\\n",
    "    \"/home/orthogonull/a_MHR/a_research/a_gitResearch/git_ignored/imagingAnalysis/data/2_tidyFormat/mouse*.csv\"))\n",
    "print(\"data files: \\n\", dataFiles)\n",
    "\n",
    "\n",
    "print(\"\\n loading and appending to prior pandas data frame\")\n",
    "dataLst = []\n",
    "for file in dataFiles:\n",
    "    print(file)\n",
    "    dataLst.append(loadTidy(file))\n",
    "df = pd.concat(dataLst)\n",
    "\n",
    "print('finished loading')\n",
    "\n",
    "############# ALL DATA STORED HERE IN DF\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching over entire data set to get range of various IDs for data (used in subsequent loops)\n",
      "dates date\n",
      "animals animal\n",
      "sessions session\n",
      "maxTrials trial\n",
      "stimuli stimulus\n",
      "{'dates': array(['2017_05_00'], \n",
      "      dtype='<U10'), 'animals': array([1, 3, 4, 5, 7]), 'sessions': array([1, 2, 3]), 'maxTrials': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "       18, 19, 20, 21]), 'stimuli': array(['USS', 'baseline', 'female', 'male', 'mineral oil odor',\n",
      "       'peanut odor', 'pred odor', 'rat', 'tone', 'toy'], \n",
      "      dtype='<U16')}\n"
     ]
    }
   ],
   "source": [
    "## survey/search data to prepare for split operation\n",
    "metaStrs = [['dates','date'],['animals','animal'],['sessions','session'],['maxTrials','trial'],['stimuli','stimulus']]\n",
    "\n",
    "print(\"searching over entire data set to get range of various IDs for data (used in subsequent loops)\") \n",
    "\n",
    "## this dictionary holds useful info regarding the range of inputs to loop/search over subsequently\n",
    "metaDct = {}\n",
    "for a,b in metaStrs:\n",
    "    print(a,b)\n",
    "    metaDct[a] = np.unique(df[b].tolist())\n",
    "print(metaDct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### USER PARAMETERS #########\n",
    "threshTPs_stdFromMean = 0.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('USS', 'baseline')\n",
      "stimuli comparison num:  1\n",
      "animal:  1\n",
      "session: 1\n",
      "USS baseline\n",
      "trial IDs for each stimulus type [ 5 10 16] [ 1  8 15]\n",
      "[[ 1117.  1116.  1117.]\n",
      " [  370.   363.  1476.]]\n",
      "trial numbers match\n",
      "checking approx num of time points\n",
      "DISCARDED: variance in trial length is above the user's threshold\n",
      "########\n",
      "\n",
      "stimuli comparison num:  1\n",
      "animal:  3\n",
      "session: 1\n",
      "USS baseline\n",
      "trial IDs for each stimulus type [ 4 11 17] [ 1  8 15]\n",
      "[[ 1267.  1127.  1123.]\n",
      " [  674.   682.   678.]]\n",
      "trial numbers match\n",
      "checking approx num of time points\n",
      "\n",
      "stimulus: USS\n",
      "selected minTPs:  674\n",
      "appending same neurons in trial:  4\n",
      "same stim: (30, 674)\n",
      "appending same neurons in trial:  11\n",
      "same stim: (30, 1348)\n",
      "appending same neurons in trial:  17\n",
      "same stim: (30, 2022)\n",
      "\n",
      "stimulus: baseline\n",
      "selected minTPs:  674\n",
      "appending same neurons in trial:  1\n",
      "same stim: (30, 674)\n",
      "appending same neurons in trial:  8\n",
      "same stim: (30, 1348)\n",
      "appending same neurons in trial:  15\n",
      "same stim: (30, 2022)\n",
      "(30, 2022) (30, 2022)\n",
      "stimA, stimB (30, 2022) (30, 2022)\n",
      "X: (60, 2022)\n",
      "y: (60,)\n",
      "k fold partitioning\n",
      "training SVM\n",
      "testing SVM\n",
      "\n",
      "\n",
      "session: 2\n",
      "USS baseline\n",
      "trial IDs for each stimulus type [ 6 12 16] [ 1  8 15]\n",
      "[[  918.   894.  1068.]\n",
      " [  681.   732.   682.]]\n",
      "trial numbers match\n",
      "checking approx num of time points\n",
      "\n",
      "stimulus: USS\n",
      "selected minTPs:  681\n",
      "appending same neurons in trial:  6\n",
      "same stim: (35, 681)\n",
      "appending same neurons in trial:  12\n",
      "same stim: (35, 1362)\n",
      "appending same neurons in trial:  16\n",
      "same stim: (35, 2043)\n",
      "\n",
      "stimulus: baseline\n",
      "selected minTPs:  681\n",
      "appending same neurons in trial:  1\n",
      "same stim: (35, 681)\n",
      "appending same neurons in trial:  8\n",
      "same stim: (35, 1362)\n",
      "appending same neurons in trial:  15\n",
      "same stim: (35, 2043)\n",
      "(35, 2043) (35, 2043)\n",
      "stimA, stimB (35, 2043) (35, 2043)\n",
      "X: (70, 2043)\n",
      "y: (70,)\n",
      "k fold partitioning\n",
      "training SVM\n",
      "testing SVM\n",
      "\n",
      "\n",
      "session: 3\n",
      "USS baseline\n",
      "trial IDs for each stimulus type [ 3 14 17] [ 1  8 15]\n",
      "[[ 1019.  1087.  1156.]\n",
      " [  677.   679.   694.]]\n",
      "trial numbers match\n",
      "checking approx num of time points\n",
      "\n",
      "stimulus: USS\n",
      "selected minTPs:  677\n",
      "appending same neurons in trial:  3\n",
      "same stim: (34, 677)\n",
      "appending same neurons in trial:  14\n",
      "same stim: (34, 1354)\n",
      "appending same neurons in trial:  17\n",
      "same stim: (34, 2031)\n",
      "\n",
      "stimulus: baseline\n",
      "selected minTPs:  677\n",
      "appending same neurons in trial:  1\n",
      "same stim: (34, 677)\n",
      "appending same neurons in trial:  8\n",
      "same stim: (34, 1354)\n",
      "appending same neurons in trial:  15\n",
      "same stim: (34, 2031)\n",
      "(34, 2031) (34, 2031)\n",
      "stimA, stimB (34, 2031) (34, 2031)\n",
      "X: (68, 2031)\n",
      "y: (68,)\n",
      "k fold partitioning\n",
      "training SVM\n",
      "testing SVM\n",
      "\n",
      "\n",
      "########\n",
      "\n",
      "stimuli comparison num:  1\n",
      "animal:  4\n",
      "session: 1\n",
      "USS baseline\n",
      "trial IDs for each stimulus type [ 4 11] []\n",
      "[[ 1137.  1113.]\n",
      " [   nan    nan]]\n",
      "DISCARDED: mismatching numbers of trials per stimulus type for this animal/session\n",
      "########\n",
      "\n",
      "stimuli comparison num:  1\n",
      "animal:  5\n",
      "session: 1\n",
      "USS baseline\n",
      "trial IDs for each stimulus type [6 9] []\n",
      "[[ 1154.  1115.]\n",
      " [   nan    nan]]\n",
      "DISCARDED: mismatching numbers of trials per stimulus type for this animal/session\n",
      "########\n",
      "\n",
      "stimuli comparison num:  1\n",
      "animal:  7\n",
      "session: 1\n",
      "USS baseline\n",
      "trial IDs for each stimulus type [ 2 14] []\n",
      "[[ 1030.  1039.]\n",
      " [   nan    nan]]\n",
      "DISCARDED: mismatching numbers of trials per stimulus type for this animal/session\n",
      "########\n",
      "\n",
      "('USS', 'female')\n",
      "stimuli comparison num:  2\n",
      "animal:  1\n",
      "session: 1\n",
      "USS female\n",
      "trial IDs for each stimulus type [ 5 10 16] [ 4 11 20]\n",
      "[[ 1117.  1116.  1117.]\n",
      " [ 1126.  1245.  1112.]]\n",
      "trial numbers match\n",
      "checking approx num of time points\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-fc8c24b26c5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials_stimA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrials_stimB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mtmp_inds_trunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_animalSession\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trial'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_animalSession\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timePt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mminTPs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mtmp_df_trunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_animalSession\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp_inds_trunc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0mtruncLst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_df_trunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mdf_trunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncLst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/orthogonull/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2054\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/orthogonull/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2096\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2098\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2099\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/orthogonull/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, convert, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   1816\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                                    convert=True, verify=True)\n\u001b[0m\u001b[1;32m   1818\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/orthogonull/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   4007\u001b[0m                                 'the axis length')\n\u001b[1;32m   4008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4009\u001b[0;31m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4010\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[1;32m   4011\u001b[0m                                     axis=axis, allow_dups=True)\n",
      "\u001b[0;32m/home/orthogonull/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, allow_fill, fill_value, **kwargs)\u001b[0m\n\u001b[1;32m   1736\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0mtaken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1738\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1740\u001b[0m     def _assert_take_fillable(self, values, indices, allow_fill=True,\n",
      "\u001b[0;32m/home/orthogonull/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_shallow_copy\u001b[0;34m(self, values, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_attributes_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mattributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_shallow_copy_with_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/orthogonull/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_simple_new\u001b[0;34m(cls, values, name, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_identity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get all pairs of stimuli\n",
    "stimCmbTpl = tuple(combinations(metaDct['stimuli'],2)) \n",
    "\n",
    "######### MAIN LOOP ##########\n",
    "totalNumComparisons = 0;\n",
    "for (stimA, stimB) in stimCmbTpl:\n",
    "    print((stimA,stimB))\n",
    "    totalNumComparisons += 1\n",
    "    \n",
    "    ## get all data for both trial types\n",
    "    indsBoth = (df['stimulus']==stimA) | (df['stimulus']==stimB)\n",
    "    df_bothStimuli = df[indsBoth]\n",
    "\n",
    "    #### select data by animals and sessions\n",
    "    for animal in metaDct['animals']:\n",
    "        print(\"stimuli comparison num: \", totalNumComparisons)\n",
    "        print('animal: ', animal)\n",
    "        for session in metaDct['sessions']:\n",
    "            print('session:', session)\n",
    "            \n",
    "            ## return subselection of data where the same neurons were recorded\n",
    "            inds_animalSession = (df_bothStimuli['animal'] == animal) & (df_bothStimuli['session'] == session)\n",
    "            df_animalSession = df_bothStimuli[inds_animalSession]\n",
    "            \n",
    "            # get lists of trial IDs matching stimuli\n",
    "            trials_stimA, trials_stimB = getListsOfTrialIDs(df_animalSession)\n",
    "            \n",
    "            #### skip this comparison <-- if the data don't match in number of trials \n",
    "            numTimePtsPerTrial = getNumTimePtsPerTrial(df_animalSession,trials_stimA,trials_stimB)\n",
    "            if areNumTrialsPerStimulusEqual(numTimePtsPerTrial)==False:\n",
    "                break     \n",
    "                \n",
    "            #### skip this comparison <-- if the data don't match in approx number of timePts\n",
    "            if areNumTimePtsPerTrialSimilar(numTimePtsPerTrial) == False:\n",
    "                break\n",
    "                \n",
    "            ## truncate longer trials to shortest trial and save to new df\n",
    "            minTPs, maxTPs, meanTPs, stdTPs = timePtStats(numTimePtsPerTrial)\n",
    "            truncLst = []\n",
    "            for trial in np.concatenate((trials_stimA,trials_stimB)):\n",
    "                tmp_inds_trunc = (df_animalSession['trial']==trial) & (df_animalSession['timePt'] <= minTPs)\n",
    "                tmp_df_trunc = df_animalSession[tmp_inds_trunc]\n",
    "                truncLst.append(tmp_df_trunc)\n",
    "            df_trunc = pd.concat(truncLst)\n",
    "                    \n",
    "            #### concatenate same cells \n",
    "            ### loop over and concatenate neurons into the same row if they're the same neuron and stimuli \n",
    "            ##      (ie mouse, session, stimuli)\n",
    "            neuronArr_anmlSess_stimA, neuronArr_anmlSess_stimB = sameNeuronConcat(df_trunc,minTPs)\n",
    "            print(np.shape(neuronArr_anmlSess_stimA), np.shape(neuronArr_anmlSess_stimB))\n",
    "            \n",
    "            ######### SVM #########\n",
    "            \n",
    "            ## create SVM format input by concatenating both classes (stimuli types); y is the labels\n",
    "            print(\"stimA, stimB\",np.shape(neuronArr_anmlSess_stimA), np.shape(neuronArr_anmlSess_stimB))\n",
    "            X = np.concatenate((neuronArr_anmlSess_stimA, neuronArr_anmlSess_stimB), axis = 0)\n",
    "            y = np.empty((neuronArr_anmlSess_stimA.shape[0]+neuronArr_anmlSess_stimB.shape[0]))\n",
    "            y[:neuronArr_anmlSess_stimA.shape[0]] = 0\n",
    "            y[neuronArr_anmlSess_stimB.shape[0]:] = 1\n",
    "            print(\"X:\", X.shape)\n",
    "            print(\"y:\", y.shape)\n",
    "            \n",
    "            print(\"k fold partitioning\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "            \n",
    "            print(\"training SVM\")\n",
    "            clf = svm.SVC(kernel='linear')\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            print(\"testing SVM\")\n",
    "            \n",
    "                \n",
    "            print('\\n')\n",
    "        print('########\\n')\n",
    "\n",
    "print('total number of comparisons: ', totalNumComparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "test = np.asarray([[4,3,2,1],[1,2,3,4]])\n",
    "test.shape[0]\n",
    "print(test.shape)\n",
    "print(test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.asarray([[0,1,2,3],[0,1,2,3]])\n",
    "print(test)\n",
    "print(np.shape(test))\n",
    "test = np.asarray([0,1,2,3])\n",
    "print(test)\n",
    "print(np.shape(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                     tmp_trialInds = (data['trial']==trial) \n",
    "#                     print(np.sum(tmp_trialInds))\n",
    "#                     tmp_mat = data[tmp_trialInds].as_matrix()\n",
    "#                     print(tmp_mat)\n",
    "#                     print(type(tmp_neuronConcatArr))\n",
    "#                     np.append(tmp_neuronConcatArr,tmp_mat)\n",
    "#                     print(tmp_neuronConcatArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testInds = (df['animal']==1) & (df['session']==1) & (df['stimulus']=='USS') & (df['trial']==5)\n",
    "print(np.sum(testInds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.unique(df_anmlSessStimA[df_anmlSessStimA['trial'] == trialA].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# gb = df.groupby(['stimulusType']).get_group('rat')\n",
    "\n",
    "stimGrouped = df.groupby('stimulusType')\n",
    "ratGrpd = stimGrouped.get_group('rat')\n",
    "\n",
    "print(ratGrpd)\n",
    "\n",
    "print('reached end of file')\n",
    "\n",
    "gb = df.groupby('stimulusType')\n",
    "\n",
    "df_means = gb.apply(np.mean)\n",
    "df_means\n",
    "\n",
    "for stimType in gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratData = df.loc[df['stimulusType'] == 'rat',:]\n",
    "ussData = df.loc[df['stimulusType'] == 'USS',:]\n",
    "\n",
    "print(ussData)\n",
    "\n",
    "# slicing\n",
    "df_big_force = df.loc[df['impact force (mN)'] > 1000, :]\n",
    "\n",
    "df = pd.concat((df_low, df_high), axis=1)\n",
    "\n",
    "# Specify indices we want (note parentheses holding each Boolean)\n",
    "inds = (df['food density'] == 'high') & (df['cross-sectional area (sq micron)'] > 2000)\n",
    "\n",
    "# Pull out areas\n",
    "df.loc[inds, 'cross-sectional area (sq micron)']\n",
    "\n",
    "df.corr()\n",
    "\n",
    "\n",
    "# Rename the impact force column\n",
    "df = df.rename(columns={'impact force (mN)': 'impf'})\n",
    "\n",
    "\n",
    "\n",
    "# Write out DataFrame\n",
    "df.to_csv('xa_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
